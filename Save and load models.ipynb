{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b094a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15e8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b42e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an example dataset\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28*28)/255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28*28)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae78d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define a model\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e202e91",
   "metadata": {},
   "source": [
    "# Save checkpoints during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19604a",
   "metadata": {},
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9043cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint', 'cp.ckpt.data-00000-of-00001', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fdd64",
   "metadata": {},
   "source": [
    "As long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights.\n",
    "\n",
    "Now rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ff3b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3868 - sparse_categorical_accuracy: 0.0750 - 119ms/epoch - 4ms/step\n",
      "Untrained model, accuracy:  7.50%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2029dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4256 - sparse_categorical_accuracy: 0.8660 - 47ms/epoch - 1ms/step\n",
      "Restored model, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "#re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1558ce",
   "metadata": {},
   "source": [
    "# Checkpoint callback options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96766600",
   "metadata": {},
   "source": [
    "The callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n",
    "\n",
    "Train a new model, and save uniquely named checkpoints once every five epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66d2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: saving model to training_2\\cp-0005.ckpt\n",
      "\n",
      "Epoch 10: saving model to training_2\\cp-0010.ckpt\n",
      "\n",
      "Epoch 15: saving model to training_2\\cp-0015.ckpt\n",
      "\n",
      "Epoch 20: saving model to training_2\\cp-0020.ckpt\n",
      "\n",
      "Epoch 25: saving model to training_2\\cp-0025.ckpt\n",
      "\n",
      "Epoch 30: saving model to training_2\\cp-0030.ckpt\n",
      "\n",
      "Epoch 35: saving model to training_2\\cp-0035.ckpt\n",
      "\n",
      "Epoch 40: saving model to training_2\\cp-0040.ckpt\n",
      "\n",
      "Epoch 45: saving model to training_2\\cp-0045.ckpt\n",
      "\n",
      "Epoch 50: saving model to training_2\\cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18913286ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Calculate the number of batches per epoch\n",
    "import math\n",
    "n_batches = len(train_images)/batch_size\n",
    "n_batches = math.ceil(n_batches)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5*n_batches\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    verbose=0,\n",
    "    validation_data=(test_images,test_labels),\n",
    "    callbacks=[cp_callback],\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bfa2ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29bc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e719f443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4750 - sparse_categorical_accuracy: 0.8790 - 108ms/epoch - 3ms/step\n",
      "Restored model, accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "#To test, reset the model, and load the latest checkpoint:\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86eb341",
   "metadata": {},
   "source": [
    "# Manually save weights..\n",
    "\n",
    "To save weights manually, use tf.keras.Model.save_weights. By default, tf.keras—and the Model.save_weights method in particular—uses the TensorFlow Checkpoint format with a .ckpt extension. To save in the HDF5 format with a .h5 extension, refer to the Save and load models guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the weights\n",
    "# model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# # Create a new model instance\n",
    "# model = create_model()\n",
    "\n",
    "# # Restore the weights\n",
    "# model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cd19b",
   "metadata": {},
   "source": [
    "# Save the entire model\n",
    "Call tf.keras.Model.save to save a model's architecture, weights, and training configuration in a single model.keras zip archive.\n",
    "\n",
    "An entire model can be saved in three different file formats (the new .keras format and two legacy formats: SavedModel, and HDF5). Saving a model as path/to/model.keras automatically saves in the latest format. .keras is recommanded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df12ad7",
   "metadata": {},
   "source": [
    "# New high-level .keras format\n",
    "The new Keras v3 saving format, marked by the .keras extension, is a more simple, efficient format that implements name-based saving, ensuring what you load is exactly what you saved, from Python's perspective. This makes debugging much easier, and it is the recommended format for Keras.\n",
    "\n",
    "The section below illustrates how to save and restore the model in the .keras format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92241767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1968 - sparse_categorical_accuracy: 0.6570\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8830\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2808 - sparse_categorical_accuracy: 0.9370\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2171 - sparse_categorical_accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images,train_labels, epochs=5)\n",
    "\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ade95f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Reload a fresh Keras model from the .keras zip archive:\n",
    "\n",
    "new_model = tf.keras.models.load_model('my_model.keras')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51ccee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4177 - sparse_categorical_accuracy: 0.8660 - 117ms/epoch - 4ms/step\n",
      "Restored model, accuracy: 86.60%\n",
      "32/32 [==============================] - 0s 913us/step\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.popredict(test_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c0d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
